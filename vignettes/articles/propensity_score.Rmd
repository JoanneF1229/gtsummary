---
title: "propensity_score"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## Introduction

RCT are considered the goal standard approach for estimating treatment effects. Random allocation ensures that treatment assignment will not be confounded by either measured or unmeasured baseline characteristics. In observational or nonrandomized studies, treatment selection is often accompanied by subject characteristics. Propensity score (PS) is one approach to reduce the effects of confounding in observational studies. PS is therefore a balancing score. Conditional on PS, the distribution of observed baseline characteristics will be similar between treated and untreated subjects.



```{r trial, echo = F}
# options(gtsummary.as_gt.addl_cmds = "gt::tab_options(table.font.size = 'small', data_row.padding = gt::px(1))")

library(tidyverse)
library(gtsummary)

# theme_gtsummary_journal(journal = "jama")

theme_gtsummary_compact()

data(trial)
```

## Steps to consider prior to matching  

- Use `tbl_summary` to examine collected baseline characteristics between treated and un-treated groups

SMD (standardized mean difference) is the most commonly used statistic to examine balance diagnostics https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6351359/

Variables with abs(SMD) > 0.1 is indicative of data imbalance between the groups.   
- Use `add_difference()` and `method`= smd to compute the SMD between the two groups.  SMD is calculated using the `smd()` function in package `smd`. 

From the summary table, age and grade have SMD < 0.1. However, there are some imbalanced between groups on marker and stage. In addition, we also didn't compute SMD for response and death since these are the outcomes. -use  `include()` to omit.


```{r pre_match_smd}
trial %>% select(trt, age, marker, stage, grade, response, death) %>%
  tbl_summary(
    by = trt,
    statistic =
      list(all_continuous() ~ "{mean} ({sd})",
           all_dichotomous() ~ "{p}%"),
    missing = "no"
  ) %>%
  add_n() %>%
  add_difference(everything() ~ "smd",
                 # no need to show SMD for outcomes
                 include = -c(response, death)) %>%
  # rename Difference to SMD
  modify_header(estimate ~ "**SMD**") %>%
  # remove 95% CI
  modify_column_hide(columns = ci) 

```

```{r, echo = FALSE}
##For groups more than 2 levels. Function for pairwise smd


#pairwise_smd <- function(data, variable, by, ...) {
  #data <- 
    #dplyr::select(data, all_of(c(variable, by))) %>%
    #rlang::set_names(c("variable", "by")) %>%
    #dplyr::filter(complete.cases(.)) %>%
    #arrange(desc(.data$by))
  
  #tibble(exclude = unique(data$by)) %>%
    #mutate(
      #include = map_chr(.data$exclude, ~unique(data$by) %>% setdiff(.x) %>% paste(collapse = " vs. ")),
     # data_subset = 
        #map(
          #.data$exclude, 
          #~data %>%
           # filter(!.data$by  %in% .x) %>%
           # mutate(by = factor(.data$by))
       # ),
      #smd = map_dbl(.data$data_subset, ~smd::smd(.x$variable, .x$by)$estimate)
    #) %>%
    #select(include, smd) %>%
    #spread(include, smd)
#}

#tbl <-
  #trial %>%
  #select(age, grade, stage) %>%
  #tbl_summary(
   # by = grade,
    #statistic = list(all_continuous() ~ "{mean} ({sd})"),
   # missing = "no"
  #) %>%
  #add_stat(fns = everything() ~ pairwise_smd)


```

## Constructing PS score
Logistic regression model is the most common method to construct the propensity score to predict the probability of receiving the treatment

```{r PSscore }

# make a complete case dataset for PS model 
trial1 <-trial %>% 
  # add ID
  mutate(ID = row_number()) 

df.ps <- trial1 %>%
  # select only matching variables and trt
  dplyr::select(ID, trt, age, marker, stage, grade) %>%
  # Exclude rows with NA
  na.omit() %>%
  # merge outcomes
  left_join(., trial1 %>% select(ID, response, death, ttdeath), 
            by = "ID") %>%
  # y response variable needs to be 0, 1, Drug B is 1 (treated)
  mutate (trt_num=ifelse(trt=='Drug A',0,1)) 


# Construct PS model 
m_ps <- glm(trt_num ~ age + marker + stage +grade, 
            family = binomial(), data = df.ps)


## Summarize the PS findings
m_ps %>% tbl_regression(exponentiate = TRUE)



#Examine the region of common support

prs_df <- data.frame(pr_score = stats::predict(m_ps, type = "response"),
                     drug.B= m_ps$model$trt_num)

labs <- paste("Actual type of drug received:", c("Drug B", "Drug A"))
prs_df %>%
  mutate(drug.B = ifelse(drug.B== 1, labs[1], labs[2])) %>%
  ggplot(aes(x = pr_score)) +
  geom_histogram(color = "white") +
  facet_wrap(~drug.B ) +
  xlab("Probability of being treated with drug B") +
  theme_bw()


```

-Before applying the estimated PS (either through matching, stratification or inverse probability weight), it is important to examine the region of common support.  If the two groups do not have sufficient common region (i.e, the distributions  are total mirror imaging of each other), then applying PS analysis may not be feasible. 





## PS Matching
There are different algorithm for matching: optimal matching (Bersekas, 1991), Greedy's nearest neighbour matching (with or without replacement). See Austin (2012) for detailed discussion and comparison of different algorithms for matching on the propensity score. The R pckage `MatchIt` written by Noah Greifer, offers different methods for matching. Complete vignette on this package can be found here: https://cran.r-project.org/web/packages/MatchIt/vignettes/MatchIt.html#assessing-the-quality-of-matches]

The following codes show the 1:1 Greedy's nearest neighbour matching without replacement with a caliper of 0.25. 

Caliper is the actual maximum distance allowed by the matching algorithm. It is usually set to be a quarter of standard deviation of the propensity score. Reference on selecting the appropriate caliper canbe found here : https://doi.org/10.1093/aje/kwt212
```{r match}

library(MatchIt)


matchdat <- matchit(trt_num ~ age + marker + stage + grade, 
                    method = "nearest", 
                    distance = "glm",
                    link = "logit",
                    data = df.ps,
                    caliper = 0.25,  # starting typically with 0.25
                    std.caliper = T,
                    replace = FALSE
)

# Extract matched data for analysis
df.match  <- match.data(matchdat)

```

## Summarize the matching
After matching, we can use ` tbl_summary ` to assess the balance of covariates between the matched group. Alternative way is to use ` summary()` from `MatchIt`. Distributions of propensity score for the matched and unmatched can be visualized using the ` plot()` with ` type='jitter'`. Assessing the balance of covariates before and after matching can be done using the empirical quantile-quantile (eQQ) plot with ` type='qq'`


### Post-matching SMD
```{r postmatchSMD}

## PS matched

df.match %>%
  dplyr::select(age,marker,stage,grade, trt) %>%

  tbl_summary(by = "trt") %>%
  add_difference(
    test = everything() ~ "smd",
    estimate_fun = list(everything() ~ function(x)
      style_sigfig(x, digits = 3))
  ) %>%
  # rename Difference to SMD
  modify_header(estimate ~ "**SMD**") %>%
  # remove 95%CI
  modify_column_hide(columns = ci)

```


### Additional ways to check balance
```{r}
a<-summary(matchdat)

#Make a$nn to a dataframe?
a$nn %>% as.data.frame() %>% tibble::rownames_to_column() %>%   gt::gt() %>% gt::tab_header("Table: Sample sizes")

```
ESS is the effective sample size.  The table shows how much of the data has been matched.  We were able to find a matched pair for the majority of the patients.


#### Visualize the distributions of PS for the matching groups
```{r}
plot(matchdat, type = 'qq', interactive = FALSE)
```

QQ plot is assessing the balance of the covariates.  If points deviate from 45 degree line, it means there is still imbalance between the groups for that covariate. 


```{r}
plot(matchdat, type = 'jitter', interactive = FALSE)
```


Jitter plot shows the distribution of PS for the matched and unmatched of the control and treated groups.  This is a helpful visualtizaion to show if the  unmatched were very different between cases and controls



<br>

### Strategy to improve balance between groups 
Parameters within matchit can be tweaked to help improve matching. 
  - For example, relaxing or tightening the maximum caliper width will affect how closely the pairs are matched may improve the overall balance. 
  - Choosing a different matching algorithm, for example, the default is to match the largest (`m.order` = "largest") matching takes place in descending order of distance measures.   
  - re-specify the PS model with additional covarites
  
If matching does not improve, consider a different matching strategy.
Below we will show the matching weights methods.  



<br>


## Matching weights (uses package Matching)

The matching weights method is a weighting analogue to the 1:1 pairwise matching (https://pubmed.ncbi.nlm.nih.gov/23902694/). 

The concept of matching weights is similar to the inverse probability treatment weight. The propensity score matching weight is defined as the smaller of the predicted probabilities of receiving or not receiving the treatment over the predicted probability of being assigned to the arm the patient is actually in. 

Use `svydesign` to specify the matching weights

```{r}
library(Matching)
library(survey)

## Using the complete case data and fitted propensity model constructed above 
dat = df.ps #Drug B is 1
psModel = m_ps 


## Predicted probability of being assigned to group1
dat$pgrp1 <- predict(psModel, type = "response")
## Predicted probability of being assigned to group2
dat$pgrp2 <- 1 - dat$pgrp1

## Predicted probability of being assigned to the
## treatment actually assigned (either group1 or group2)
dat$pAssign <- NA
dat$pAssign[dat$trt_num == 1] <- dat$pgrp1[dat$trt_num  == 1]
dat$pAssign[dat$trt_num == 0] <- dat$pgrp2[dat$trt_num == 0]

## Smaller of pgrp1 vs pgrp2 for matching weight
dat$pMin <- pmin(dat$pgrp1, dat$pgrp2)

## Propensity score matching weight
dat$mw <- dat$pMin / dat$pAssign

## Weighted data
datSvy = svydesign(ids = ~ 1, data = dat, weights = ~ mw)

```

## Post-matching weights SMD

Use tbl_svysummary to summarize the match weighted data and calculate SMD.  

```{r}

datSvy %>% 
  tbl_svysummary(by = "trt",
                 include = c(age,marker,stage,grade)) %>%
  add_difference(test = everything() ~ "smd",
                 estimate_fun = list(
                   everything() ~ function(x) style_sigfig(x, digits = 3))) %>%
  # rename Difference to SMD
  modify_header(estimate ~ "**SMD**") %>%
  # remove 95%CI
  modify_column_hide(columns = ci)


```


Note that effective sample sizes were rounded to whole numbers for convenience but should not be interpreted as the number of patients because  some patient may only be contributing a portion of his/her information.  Therefore, the focus should be on the comparison of percentages in each treatment group.   



## Outcome analysis

### PS 1:1 matched  

#### Response
```{r}

# Binary outcome
glm(response ~ trt,
    family = binomial,
    data = df.match) %>% tbl_regression(exponentiate = TRUE)


```

#### Survival outcome
```{r}
library(survival)
# Estimating using the cluster robust standard error
coxMatchedclust <- coxph(Surv(ttdeath, death) ~ trt,
                         robust = TRUE,
                         weights = weights,
                         cluster = subclass,
                         data = df.match
) %>% tbl_regression(exponentiate = TRUE)


# Frailty model
coxMatchedfrail <- coxph(Surv(ttdeath, death) ~ trt + frailty(subclass),
                    data = df.match) %>% tbl_regression(exponentiate = TRUE, include = trt)

tbl_merge(list(coxMatchedclust ,coxMatchedfrail),
    tab_spanner = c("**Marginal HR model**", "**Frailty model**"))


```



### Matching weights  

#### Response
```{r}
glmWeighted <- svyglm(response ~ trt,
                      family  = quasibinomial(),
                      design    = datSvy)
    
tbl_regression(glmWeighted, exponentiate = TRUE)

```


#### Survival outcome
```{r}
coxWeighted <- svycoxph(Surv(ttdeath, death) ~ trt,
                        design = datSvy)

tbl_regression(coxWeighted, exponentiate = TRUE)


```




## Conclusions
Matching often involves a tradeoff among balance, generalization, and sample size. The main advantage of the propensity score matching is it allows the researchers to design and estimate the average treatment effect in the treated from observational or nonrandomized study by forming balanced matched pairs that share the similarly value of the propensity score and minimizing the effect of confounding due to non-random allocation of treatment. However, some concerns of PSM includes but not limited to 1) requires large samples with substantial overlap in PS between treated and control; 2) More tweaking is needed by user to achieve balance; 3) PSM can only accounts for observed (observable) covariates and not latent characteristics. 

Matching weights can offer a more efficient estimation and more accurate variance calculation.  It achieves balance with little tweaking required by user. It uses data from all patients, with no exclusion due to difficulty of matching but patients at the extreme end of the PS spectrum are being downweighted and contribute very little to the final estimation.
Therefore, the matched sample is considered a pseudo-population where patients are only contributing a portion of their data.  This concept may be challenging to understand for investigators.
